SVM can be used for Classification and Regression. But mostly used for Classification.

Support Vectors are simply the co-ordinates of individual observation. 
Support Vector Machine is a frontier which best segregates the two classes

How does segregating ?
  It is segregating using hyper-plane.
  
Here, maximizing the distances between nearest data point (either class) 
and hyper-plane will help us to decide the right hyper-plane. This distance is called as Margin.

Another lightning reason for selecting the hyper-plane with higher margin is robustness

In SVM, it is easy to have a linear hyper-plane between these two classes. But, another burning question which arises is, 
should we need to add this feature manually to have a hyper-plane. No, SVM has a technique called the kernel trick. 
These are functions which takes low dimensional input space and transform it to a higher dimensional space 
i.e. it converts not separable problem to separable problem, these functions are called kernels.


